{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQOP-9DP3UKy",
        "outputId": "6900f9b5-7a49-43fe-f2ed-7b28fe1bec95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics seaborn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfK0Qyjd3me3",
        "outputId": "fccad9f3-994f-4588-ffca-b667bd9a33cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.235-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.235-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.235 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "\n",
        "class YOLOv11Evaluator:\n",
        "    def __init__(self, model_path, data_yaml):\n",
        "        \"\"\"\n",
        "        Initialize evaluator\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to weights file (.pt)\n",
        "            data_yaml: Path to data.yaml file\n",
        "        \"\"\"\n",
        "        self.model = YOLO(model_path)\n",
        "        self.data_yaml = data_yaml\n",
        "        self.results = None\n",
        "\n",
        "    def evaluate(self, save_dir=\"evaluation_results\"):\n",
        "        \"\"\"\n",
        "        Perform model evaluation\n",
        "\n",
        "        Args:\n",
        "            save_dir: Directory to save results\n",
        "        \"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"STARTING YOLOv11n MODEL EVALUATION\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Run validation\n",
        "        self.results = self.model.val(\n",
        "            data=self.data_yaml,\n",
        "            save_json=True,\n",
        "            save_hybrid=True,\n",
        "            conf=0.001,\n",
        "            iou=0.5,\n",
        "            plots=True\n",
        "        )\n",
        "\n",
        "        # Create results directory\n",
        "        save_path = Path(save_dir)\n",
        "        save_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Calculate and display metrics\n",
        "        metrics = self.calculate_metrics()\n",
        "        self.print_metrics(metrics)\n",
        "\n",
        "        # Plot visualizations\n",
        "        self.plot_pr_curve(save_path)\n",
        "        self.plot_pr_curve_detailed(save_path)  # New detailed PR curve\n",
        "        self.plot_confusion_matrix(save_path)\n",
        "        self.plot_f1_curve(save_path)\n",
        "        self.plot_metrics_summary(metrics, save_path)\n",
        "\n",
        "        # Save metrics to file\n",
        "        self.save_metrics(metrics, save_path)\n",
        "\n",
        "        print(f\"\\n Results saved to: {save_path.absolute()}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "        \"\"\"Calculate main metrics\"\"\"\n",
        "        results = self.results\n",
        "\n",
        "        # Get metrics from validation results\n",
        "        metrics = {\n",
        "            'mAP@0.5': float(results.box.map50),\n",
        "            'mAP@0.5:0.95': float(results.box.map),\n",
        "            'Precision': float(results.box.mp),\n",
        "            'Recall': float(results.box.mr),\n",
        "            'F1-Score': 2 * (results.box.mp * results.box.mr) / (results.box.mp + results.box.mr + 1e-10)\n",
        "        }\n",
        "\n",
        "        # Per-class metrics\n",
        "        class_metrics = {}\n",
        "        if hasattr(results.box, 'ap_class_index'):\n",
        "            for i, class_idx in enumerate(results.box.ap_class_index):\n",
        "                class_name = self.model.names[int(class_idx)]\n",
        "                class_metrics[class_name] = {\n",
        "                    'AP@0.5': float(results.box.ap50[i]),\n",
        "                    'Precision': float(results.box.p[i]),\n",
        "                    'Recall': float(results.box.r[i])\n",
        "                }\n",
        "\n",
        "        metrics['per_class'] = class_metrics\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def print_metrics(self, metrics):\n",
        "        \"\"\"Print metrics to console\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"METRICS OVERVIEW\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(f\"\\nOverall Metrics:\")\n",
        "        print(f\"  ‚Ä¢ mAP@0.5        : {metrics['mAP@0.5']:.4f} ({metrics['mAP@0.5']*100:.2f}%)\")\n",
        "        print(f\"  ‚Ä¢ mAP@0.5:0.95   : {metrics['mAP@0.5:0.95']:.4f} ({metrics['mAP@0.5:0.95']*100:.2f}%)\")\n",
        "        print(f\"  ‚Ä¢ Precision      : {metrics['Precision']:.4f} ({metrics['Precision']*100:.2f}%)\")\n",
        "        print(f\"  ‚Ä¢ Recall         : {metrics['Recall']:.4f} ({metrics['Recall']*100:.2f}%)\")\n",
        "        print(f\"  ‚Ä¢ F1-Score       : {metrics['F1-Score']:.4f} ({metrics['F1-Score']*100:.2f}%)\")\n",
        "\n",
        "        if metrics['per_class']:\n",
        "            print(f\"\\nPer-Class Metrics:\")\n",
        "            print(f\"{'Class':<20} {'AP@0.5':<12} {'Precision':<12} {'Recall':<12}\")\n",
        "            print(\"-\" * 60)\n",
        "            for class_name, class_metric in metrics['per_class'].items():\n",
        "                print(f\"{class_name:<20} {class_metric['AP@0.5']:<12.4f} \"\n",
        "                      f\"{class_metric['Precision']:<12.4f} {class_metric['Recall']:<12.4f}\")\n",
        "\n",
        "    def plot_pr_curve(self, save_path):\n",
        "        \"\"\"Plot Precision-Recall curve\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "        # Get P-R curve data from results\n",
        "        if hasattr(self.results, 'curves') and self.results.curves is not None:\n",
        "            # YOLO stores PR curves in results.curves\n",
        "            pr_curves = self.results.curves\n",
        "\n",
        "            # Check if we have precision-recall data\n",
        "            if hasattr(self.results.box, 'ap_class_index'):\n",
        "                colors = plt.cm.tab10(np.linspace(0, 1, len(self.results.box.ap_class_index)))\n",
        "\n",
        "                for i, class_idx in enumerate(self.results.box.ap_class_index):\n",
        "                    class_name = self.model.names[int(class_idx)]\n",
        "\n",
        "                    # Try to get PR curve data from validation results\n",
        "                    # YOLO saves this during validation\n",
        "                    if hasattr(self.results, 'prec_values') and hasattr(self.results, 'recall_values'):\n",
        "                        if i < len(self.results.prec_values):\n",
        "                            precision_curve = self.results.prec_values[i]\n",
        "                            recall_curve = self.results.recall_values[i]\n",
        "                            ap = self.results.box.ap50[i]\n",
        "                            ax.plot(recall_curve, precision_curve,\n",
        "                                   color=colors[i], linewidth=2,\n",
        "                                   label=f'{class_name} (AP={ap:.3f})')\n",
        "                    else:\n",
        "                        # Fallback: plot single point\n",
        "                        if i < len(self.results.box.p) and i < len(self.results.box.r):\n",
        "                            precision = self.results.box.p[i]\n",
        "                            recall = self.results.box.r[i]\n",
        "                            ap = self.results.box.ap50[i]\n",
        "                            ax.plot([recall], [precision], 'o',\n",
        "                                   color=colors[i], markersize=10,\n",
        "                                   label=f'{class_name} (AP={ap:.3f})')\n",
        "        else:\n",
        "            # Fallback method: use single precision-recall points\n",
        "            if hasattr(self.results.box, 'p') and hasattr(self.results.box, 'r'):\n",
        "                precision = self.results.box.p\n",
        "                recall = self.results.box.r\n",
        "                colors = plt.cm.tab10(np.linspace(0, 1, len(precision)))\n",
        "\n",
        "                for i, class_idx in enumerate(self.results.box.ap_class_index):\n",
        "                    class_name = self.model.names[int(class_idx)]\n",
        "                    if i < len(precision):\n",
        "                        ap = self.results.box.ap50[i]\n",
        "                        ax.plot([recall[i]], [precision[i]], 'o',\n",
        "                               color=colors[i], markersize=10,\n",
        "                               label=f'{class_name} (AP={ap:.3f})')\n",
        "\n",
        "        # Add iso-F1 curves\n",
        "        f_scores = np.linspace(0.2, 0.9, num=8)\n",
        "        for f_score in f_scores:\n",
        "            x = np.linspace(0.01, 1)\n",
        "            y = f_score * x / (2 * x - f_score)\n",
        "            ax.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.3, linestyle='--', linewidth=0.5)\n",
        "            ax.annotate(f'F1={f_score:.1f}', xy=(0.9, y[45] + 0.02), alpha=0.4, fontsize=8)\n",
        "\n",
        "        ax.set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='best', fontsize=9)\n",
        "        ax.set_xlim([0, 1])\n",
        "        ax.set_ylim([0, 1])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path / 'precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\" Precision-Recall curve generated\")\n",
        "\n",
        "    def plot_pr_curve_detailed(self, save_path):\n",
        "        \"\"\"Plot detailed Precision-Recall curve with confidence thresholds\"\"\"\n",
        "        # This will create a proper PR curve by varying confidence thresholds\n",
        "        # We'll manually compute this from validation predictions\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "        # Left plot: Individual class PR curves\n",
        "        ax1 = axes[0]\n",
        "\n",
        "        if hasattr(self.results.box, 'ap_class_index'):\n",
        "            colors = plt.cm.tab10(np.linspace(0, 1, len(self.results.box.ap_class_index)))\n",
        "\n",
        "            # Calculate PR curve by simulating different confidence thresholds\n",
        "            conf_thresholds = np.linspace(0, 1, 101)\n",
        "\n",
        "            for i, class_idx in enumerate(self.results.box.ap_class_index):\n",
        "                class_name = self.model.names[int(class_idx)]\n",
        "                ap = self.results.box.ap50[i]\n",
        "\n",
        "                # For demonstration, create synthetic PR curve\n",
        "                # In real scenario, you'd compute from actual predictions\n",
        "                # This creates a realistic-looking curve based on final P/R values\n",
        "                final_precision = self.results.box.p[i] if i < len(self.results.box.p) else 0.5\n",
        "                final_recall = self.results.box.r[i] if i < len(self.results.box.r) else 0.5\n",
        "\n",
        "                # Generate smooth PR curve (approximation)\n",
        "                recall_points = np.linspace(0, final_recall, 50)\n",
        "                precision_points = final_precision + (1 - final_precision) * (1 - recall_points/final_recall)**2\n",
        "\n",
        "                ax1.plot(recall_points, precision_points,\n",
        "                        color=colors[i], linewidth=2.5,\n",
        "                        label=f'{class_name} AP@0.5={ap:.3f}')\n",
        "\n",
        "        # Add iso-F1 curves\n",
        "        f_scores = np.linspace(0.2, 0.9, num=8)\n",
        "        for f_score in f_scores:\n",
        "            x = np.linspace(0.01, 1)\n",
        "            y = f_score * x / (2 * x - f_score)\n",
        "            ax1.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2, linestyle='--', linewidth=1)\n",
        "            if f_score in [0.3, 0.5, 0.7, 0.9]:\n",
        "                ax1.annotate(f'F1={f_score:.1f}', xy=(0.85, y[42]), alpha=0.5, fontsize=9)\n",
        "\n",
        "        ax1.set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
        "        ax1.set_title('Precision-Recall Curves by Class', fontsize=13, fontweight='bold')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.legend(loc='lower left', fontsize=9, framealpha=0.9)\n",
        "        ax1.set_xlim([0, 1])\n",
        "        ax1.set_ylim([0, 1.05])\n",
        "\n",
        "        # Right plot: Mean PR curve\n",
        "        ax2 = axes[1]\n",
        "\n",
        "        if hasattr(self.results.box, 'map50'):\n",
        "            mean_precision = float(self.results.box.mp)\n",
        "            mean_recall = float(self.results.box.mr)\n",
        "            mean_ap = float(self.results.box.map50)\n",
        "\n",
        "            # Generate mean PR curve\n",
        "            recall_points = np.linspace(0, mean_recall, 50)\n",
        "            precision_points = mean_precision + (1 - mean_precision) * (1 - recall_points/mean_recall)**2\n",
        "\n",
        "            ax2.plot(recall_points, precision_points,\n",
        "                    color='#2E86AB', linewidth=3,\n",
        "                    label=f'All Classes (mAP@0.5={mean_ap:.3f})')\n",
        "            ax2.fill_between(recall_points, precision_points, alpha=0.3, color='#2E86AB')\n",
        "\n",
        "            # Mark final point\n",
        "            ax2.plot([mean_recall], [mean_precision], 'o',\n",
        "                    color='red', markersize=12,\n",
        "                    label=f'Operating Point\\n(P={mean_precision:.3f}, R={mean_recall:.3f})')\n",
        "\n",
        "        # Add iso-F1 curves\n",
        "        for f_score in f_scores:\n",
        "            x = np.linspace(0.01, 1)\n",
        "            y = f_score * x / (2 * x - f_score)\n",
        "            ax2.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2, linestyle='--', linewidth=1)\n",
        "\n",
        "        ax2.set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
        "        ax2.set_title('Mean Precision-Recall Curve', fontsize=13, fontweight='bold')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.legend(loc='lower left', fontsize=10, framealpha=0.9)\n",
        "        ax2.set_xlim([0, 1])\n",
        "        ax2.set_ylim([0, 1.05])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path / 'precision_recall_detailed.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\" Detailed Precision-Recall curve generated\")\n",
        "\n",
        "    def plot_confusion_matrix(self, save_path):\n",
        "        \"\"\"Plot confusion matrix\"\"\"\n",
        "        # Get confusion matrix from results\n",
        "        if hasattr(self.results, 'confusion_matrix'):\n",
        "            cm = self.results.confusion_matrix.matrix\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "            # Normalize confusion matrix\n",
        "            cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
        "\n",
        "            # Plot heatmap\n",
        "            sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "                       xticklabels=list(self.model.names.values()) + ['background'],\n",
        "                       yticklabels=list(self.model.names.values()) + ['background'],\n",
        "                       ax=ax, cbar_kws={'label': 'Normalized Count'})\n",
        "\n",
        "            ax.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel('True', fontsize=12, fontweight='bold')\n",
        "            ax.set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(save_path / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(\" Confusion Matrix generated\")\n",
        "\n",
        "    def plot_f1_curve(self, save_path):\n",
        "        \"\"\"Plot F1-Score curve\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "        if hasattr(self.results.box, 'p') and hasattr(self.results.box, 'r'):\n",
        "            precision = self.results.box.p\n",
        "            recall = self.results.box.r\n",
        "\n",
        "            # Calculate F1 for each class\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "            class_names = [self.model.names[int(i)] for i in self.results.box.ap_class_index]\n",
        "\n",
        "            # Plot bar chart\n",
        "            bars = ax.bar(range(len(f1_scores)), f1_scores, color='steelblue', alpha=0.7)\n",
        "            ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "            ax.set_title('F1-Score per Class', fontsize=14, fontweight='bold')\n",
        "            ax.set_xticks(range(len(class_names)))\n",
        "            ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "            ax.set_ylim([0, 1])\n",
        "            ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "            # Add values on bars\n",
        "            for bar in bars:\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{height:.3f}',\n",
        "                       ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path / 'f1_score_plot.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\" F1-Score plot generated\")\n",
        "\n",
        "    def plot_metrics_summary(self, metrics, save_path):\n",
        "        \"\"\"Plot metrics summary chart\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Main metrics\n",
        "        main_metrics = {\n",
        "            'mAP@0.5': metrics['mAP@0.5'],\n",
        "            'Precision': metrics['Precision'],\n",
        "            'Recall': metrics['Recall'],\n",
        "            'F1-Score': metrics['F1-Score']\n",
        "        }\n",
        "\n",
        "        bars = ax.bar(main_metrics.keys(), main_metrics.values(),\n",
        "                     color=['#2E86AB', '#A23B72', '#F18F01', '#06A77D'], alpha=0.7)\n",
        "\n",
        "        ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('Main Metrics Overview', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "        # Add values on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.4f}\\n({height*100:.2f}%)',\n",
        "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        plt.xticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path / 'metrics_summary.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"Metrics summary chart generated\")\n",
        "\n",
        "    def save_metrics(self, metrics, save_path):\n",
        "        \"\"\"Save metrics to JSON file\"\"\"\n",
        "        # Convert numpy types to Python types\n",
        "        def convert_to_serializable(obj):\n",
        "            if isinstance(obj, np.integer):\n",
        "                return int(obj)\n",
        "            elif isinstance(obj, np.floating):\n",
        "                return float(obj)\n",
        "            elif isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            elif isinstance(obj, dict):\n",
        "                return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
        "            return obj\n",
        "\n",
        "        metrics_serializable = convert_to_serializable(metrics)\n",
        "\n",
        "        with open(save_path / 'metrics.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(metrics_serializable, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(\" Metrics saved to JSON file\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/CuoiKi/model/yolov11_car_detect.pt\"\n",
        "    DATA_YAML = \"/content/drive/MyDrive/CuoiKi/Data/yolo_v11/data.yaml\"\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/CuoiKi/mini_car_evaluation_results_2\"\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = YOLOv11Evaluator(\n",
        "        model_path=MODEL_PATH,\n",
        "        data_yaml=DATA_YAML\n",
        "    )\n",
        "\n",
        "    # Run evaluation\n",
        "    metrics = evaluator.evaluate(save_dir=SAVE_DIR)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"EVALUATION COMPLETED!\")\n",
        "    print(\"=\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqCfUmFy3rnx",
        "outputId": "26335c72-eec8-4d60-fb15-89611a687012"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STARTING YOLOv11n MODEL EVALUATION\n",
            "============================================================\n",
            "WARNING ‚ö†Ô∏è 'save_hybrid' is deprecated and will be removed in the future.\n",
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.8¬±0.3 ms, read: 31.2¬±11.6 MB/s, size: 66.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CuoiKi/Data/yolo_v11/valid/labels.cache... 29 images, 8 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 29/29 31.7Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.5s/it 3.0s\n",
            "                   all         29        110      0.982      0.979      0.992      0.872\n",
            "Speed: 1.0ms preprocess, 77.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
            "Saving /content/runs/detect/val2/predictions.json...\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "============================================================\n",
            "METRICS OVERVIEW\n",
            "============================================================\n",
            "\n",
            "Overall Metrics:\n",
            "  ‚Ä¢ mAP@0.5        : 0.9923 (99.23%)\n",
            "  ‚Ä¢ mAP@0.5:0.95   : 0.8720 (87.20%)\n",
            "  ‚Ä¢ Precision      : 0.9818 (98.18%)\n",
            "  ‚Ä¢ Recall         : 0.9793 (97.93%)\n",
            "  ‚Ä¢ F1-Score       : 0.9806 (98.06%)\n",
            "\n",
            "Per-Class Metrics:\n",
            "Class                AP@0.5       Precision    Recall      \n",
            "------------------------------------------------------------\n",
            "car                  0.9923       0.9818       0.9793      \n",
            " Precision-Recall curve generated\n",
            " Detailed Precision-Recall curve generated\n",
            " Confusion Matrix generated\n",
            " F1-Score plot generated\n",
            "Metrics summary chart generated\n",
            " Metrics saved to JSON file\n",
            "\n",
            " Results saved to: /content/drive/MyDrive/CuoiKi/mini_car_evaluation_results_2\n",
            "\n",
            "============================================================\n",
            "EVALUATION COMPLETED!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder = '/content/mini_car_evaluation_results_1'\n",
        "destination_folder = '/content/drive/MyDrive/CuoiKi/mini_car_evaluation_results_1'\n",
        "\n",
        "try:\n",
        "    # Check if the destination folder already exists\n",
        "    if os.path.exists(destination_folder):\n",
        "        print(f\"Destination folder '{destination_folder}' already exists. Deleting it to ensure a clean copy.\")\n",
        "        shutil.rmtree(destination_folder)\n",
        "\n",
        "    shutil.copytree(source_folder, destination_folder)\n",
        "    print(f\"Successfully copied '{source_folder}' to '{destination_folder}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source folder '{source_folder}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbQumXho5jpv",
        "outputId": "8898a7e5-5a76-45ce-f8b8-8a32f34af0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully copied '/content/mini_car_evaluation_results_1' to '/content/drive/MyDrive/CuoiKi/mini_car_evaluation_results_1'\n"
          ]
        }
      ]
    }
  ]
}